{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "d1b9a493-401a-4bf4-9bb1-7dd8896caf14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(309, 8)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from surprise import Dataset\n",
    "from surprise.model_selection import cross_validate\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "food_data = pd.read_csv('data/food.csv')\n",
    "ratings_data = pd.read_csv('data/ratings.csv')\n",
    "\n",
    "def text_cleaning(text):\n",
    "    text = \"\".join([char for char in text if char not in string.punctuation])\n",
    "    return text\n",
    "food_data['Describe'] = food_data['Describe'].apply(text_cleaning)\n",
    "\n",
    "def create_soup(x):\n",
    "  return \" \".join([x['Describe'], x['C_Type'], x['Veg_Non']])\n",
    "\n",
    "food_data['soup'] = food_data.apply(create_soup, axis=1)\n",
    "\n",
    "# reader = Reader(rating_scale=(1, 10))\n",
    "\n",
    "df = pd.merge(ratings_data, food_data, on='Food_ID').drop_duplicates(subset='Name', keep='first').reset_index(drop=True)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b01a0010-be5a-48a6-b057-1fdf78edb387",
   "metadata": {},
   "source": [
    "## Recommender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "15afdc5a-c3ae-4972-a416-6248fe8c3aae",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    boneless skinless chicken thigh trimmed salt a...\n",
       "1    buns all purpose white flour dry yeast sugar s...\n",
       "2    whole moong beans cow ghee raisins whole milk ...\n",
       "3    cashew paste ghee khaand a sweetening agent an...\n",
       "4    pizza dough 2 boules red pepper red onion basi...\n",
       "Name: soup, dtype: object"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['soup'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "9e986f07-d3f6-444f-9100-1a7856e2efb3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(309, 8)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "ddb9d5b6-cd50-4618-88ae-251b7a391df7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(309, 1115)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import TfIdfVectorizer from scikit-learn\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#Define a TF-IDF Vectorizer Object. Remove all english stop words such as 'the', 'a'\n",
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "\n",
    "#Replace NaN with an empty string\n",
    "# metadata['soup'] = metadata['overview'].fillna('')\n",
    "\n",
    "#Construct the required TF-IDF matrix by fitting and transforming the data\n",
    "tfidf_matrix = tfidf.fit_transform(df['soup'])\n",
    "\n",
    "#Output the shape of tfidf_matrix\n",
    "tfidf_matrix.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "09645eee-ea77-43ad-be6f-a2a7a5284fff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['10', '12', '12inchthin', ..., 'zested', 'zinfandel', 'zucchini'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "3b902526-58df-4bdc-8d20-e093bb2f9e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import linear_kernel\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "\n",
    "# Compute the cosine similarity matrix\n",
    "cosine_sim = linear_kernel(tfidf_matrix, tfidf_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "6ccc0a51-fd11-4360-ab50-da6056fdd03c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(309, 309)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_sim.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "06e5f533-708a-42ef-afdc-83038733e4da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Construct a reverse map of indices and movie titles\n",
    "indices = pd.Series(df.index, index=df['Name']).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "886b62fd-18fb-4258-86f2-6ecad24b7d35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Name\n",
       "peri peri chicken satay         0\n",
       "steam bunny chicken bao         1\n",
       "green lentil dessert fudge      2\n",
       "cashew nut cookies              3\n",
       "christmas tree pizza            4\n",
       "moong dal kiwi coconut soup     5\n",
       "chicken nimbu dhaniya shorba    6\n",
       "carrot ginger soup              7\n",
       "hot chocolate                   8\n",
       "chicken and mushroom lasagna    9\n",
       "dtype: int64"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indices[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "d4df29ec-8f7b-4ca5-8e21-74b0f1e88e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations(title, cosine_sim=cosine_sim, k=5):\n",
    "    idx = indices[title]\n",
    "    print(idx)\n",
    "\n",
    "    sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "    sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "    sim_scores = sim_scores[1:k+1]\n",
    "    food_indices = [i[0] for i in sim_scores]\n",
    "    return df['Name'].iloc[food_indices]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "02d6a40b-3022-467e-8c6f-932a37b18e62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "279\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "256         chocolate doughnut\n",
       "88      chocolate nero cookies\n",
       "258    chocolate fudge cookies\n",
       "59        chocolate kaju katli\n",
       "71          chocolate marquise\n",
       "Name: Name, dtype: object"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_recommendations('chocolate lava cake')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1893f27a-42cd-4da6-ae8c-3527bce398bd",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "\n",
    "Need to find evaluation metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018ed484-72f1-401b-b53d-10ec05a39241",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
